{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d553a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📡 [1/181] AAPL\n",
      "📡 [2/181] ABNB\n",
      "📡 [3/181] ACN\n",
      "📡 [4/181] ADBE\n",
      "📡 [5/181] ADI\n",
      "📡 [6/181] ADM\n",
      "📡 [7/181] ADSK\n",
      "📡 [8/181] AKAM\n",
      "📡 [9/181] AMAT\n",
      "📡 [10/181] AMD\n",
      "📡 [11/181] AMZN\n",
      "📡 [12/181] ANET\n",
      "📡 [13/181] APH\n",
      "📡 [14/181] APTV\n",
      "📡 [15/181] AVGO\n",
      "📡 [16/181] AZO\n",
      "📡 [17/181] BBY\n",
      "📡 [18/181] BF.B\n",
      "📡 [19/181] BG\n",
      "📡 [20/181] BKNG\n",
      "📡 [21/181] CAG\n",
      "📡 [22/181] CCL\n",
      "📡 [23/181] CDNS\n",
      "📡 [24/181] CDW\n",
      "📡 [25/181] CHD\n",
      "📡 [26/181] CHTR\n",
      "📡 [27/181] CL\n",
      "📡 [28/181] CLX\n",
      "📡 [29/181] CMCSA\n",
      "📡 [30/181] CMG\n",
      "📡 [31/181] COST\n",
      "📡 [32/181] CPB\n",
      "📡 [33/181] CRM\n",
      "📡 [34/181] CRWD\n",
      "📡 [35/181] CSCO\n",
      "📡 [36/181] CTSH\n",
      "📡 [37/181] CZR\n",
      "📡 [38/181] DASH\n",
      "📡 [39/181] DDOG\n",
      "📡 [40/181] DECK\n",
      "📡 [41/181] DELL\n",
      "📡 [42/181] DG\n",
      "📡 [43/181] DHI\n",
      "📡 [44/181] DIS\n",
      "📡 [45/181] DLTR\n",
      "📡 [46/181] DPZ\n",
      "📡 [47/181] DRI\n",
      "📡 [48/181] EA\n",
      "📡 [49/181] EBAY\n",
      "📡 [50/181] EL\n",
      "📡 [51/181] ENPH\n",
      "📡 [52/181] EPAM\n",
      "📡 [53/181] EXPE\n",
      "📡 [54/181] F\n",
      "📡 [55/181] FFIV\n",
      "📡 [56/181] FICO\n",
      "📡 [57/181] FOX\n",
      "📡 [58/181] FOXA\n",
      "📡 [59/181] FSLR\n",
      "📡 [60/181] FTNT\n",
      "📡 [61/181] GDDY\n",
      "📡 [62/181] GEN\n",
      "📡 [63/181] GIS\n",
      "📡 [64/181] GLW\n",
      "📡 [65/181] GM\n",
      "📡 [66/181] GOOG\n",
      "📡 [67/181] GOOGL\n",
      "📡 [68/181] GPC\n",
      "📡 [69/181] GRMN\n",
      "📡 [70/181] HAS\n",
      "📡 [71/181] HD\n",
      "📡 [72/181] HLT\n",
      "📡 [73/181] HPE\n",
      "📡 [74/181] HPQ\n",
      "📡 [75/181] HRL\n",
      "📡 [76/181] HSY\n",
      "📡 [77/181] IBM\n",
      "📡 [78/181] INTC\n",
      "📡 [79/181] INTU\n",
      "📡 [80/181] IPG\n",
      "📡 [81/181] IT\n",
      "📡 [82/181] JBL\n",
      "📡 [83/181] K\n",
      "📡 [84/181] KDP\n",
      "📡 [85/181] KEYS\n",
      "📡 [86/181] KHC\n",
      "📡 [87/181] KLAC\n",
      "📡 [88/181] KMB\n",
      "📡 [89/181] KMX\n",
      "📡 [90/181] KO\n",
      "📡 [91/181] KR\n",
      "📡 [92/181] KVUE\n",
      "📡 [93/181] LEN\n",
      "📡 [94/181] LKQ\n",
      "📡 [95/181] LOW\n",
      "📡 [96/181] LRCX\n",
      "📡 [97/181] LULU\n",
      "📡 [98/181] LVS\n",
      "📡 [99/181] LW\n",
      "📡 [100/181] LYV\n",
      "📡 [101/181] MAR\n",
      "📡 [102/181] MCD\n",
      "📡 [103/181] MCHP\n",
      "📡 [104/181] MDLZ\n",
      "📡 [105/181] META\n",
      "📡 [106/181] MGM\n",
      "📡 [107/181] MHK\n",
      "📡 [108/181] MKC\n",
      "📡 [109/181] MNST\n",
      "📡 [110/181] MO\n",
      "📡 [111/181] MPWR\n",
      "📡 [112/181] MSFT\n",
      "📡 [113/181] MSI\n",
      "📡 [114/181] MTCH\n",
      "📡 [115/181] MU\n",
      "📡 [116/181] NCLH\n",
      "📡 [117/181] NFLX\n",
      "📡 [118/181] NKE\n",
      "📡 [119/181] NOW\n",
      "📡 [120/181] NTAP\n",
      "📡 [121/181] NVDA\n",
      "📡 [122/181] NVR\n",
      "📡 [123/181] NWS\n",
      "📡 [124/181] NWSA\n",
      "📡 [125/181] NXPI\n",
      "📡 [126/181] OMC\n",
      "📡 [127/181] ON\n",
      "📡 [128/181] ORCL\n",
      "📡 [129/181] ORLY\n",
      "📡 [130/181] PANW\n",
      "📡 [131/181] PEP\n",
      "📡 [132/181] PG\n",
      "📡 [133/181] PHM\n",
      "📡 [134/181] PLTR\n",
      "📡 [135/181] PM\n",
      "📡 [136/181] POOL\n",
      "📡 [137/181] PSKY\n",
      "📡 [138/181] PTC\n",
      "📡 [139/181] QCOM\n",
      "📡 [140/181] RCL\n",
      "📡 [141/181] RL\n",
      "📡 [142/181] ROP\n",
      "📡 [143/181] ROST\n",
      "📡 [144/181] SBUX\n",
      "📡 [145/181] SJM\n",
      "📡 [146/181] SMCI\n",
      "📡 [147/181] SNPS\n",
      "📡 [148/181] STX\n",
      "📡 [149/181] STZ\n",
      "📡 [150/181] SWKS\n",
      "📡 [151/181] SYY\n",
      "📡 [152/181] T\n",
      "📡 [153/181] TAP\n",
      "📡 [154/181] TDY\n",
      "📡 [155/181] TEL\n",
      "📡 [156/181] TER\n",
      "📡 [157/181] TGT\n",
      "📡 [158/181] TJX\n",
      "📡 [159/181] TKO\n",
      "📡 [160/181] TMUS\n",
      "📡 [161/181] TPR\n",
      "📡 [162/181] TRMB\n",
      "📡 [163/181] TSCO\n",
      "📡 [164/181] TSLA\n",
      "📡 [165/181] TSN\n",
      "📡 [166/181] TTD\n",
      "📡 [167/181] TTWO\n",
      "📡 [168/181] TXN\n",
      "📡 [169/181] TYL\n",
      "📡 [170/181] ULTA\n",
      "📡 [171/181] VRSN\n",
      "📡 [172/181] VZ\n",
      "📡 [173/181] WBA\n",
      "📡 [174/181] WBD\n",
      "📡 [175/181] WDAY\n",
      "📡 [176/181] WDC\n",
      "📡 [177/181] WMT\n",
      "📡 [178/181] WSM\n",
      "📡 [179/181] WYNN\n",
      "📡 [180/181] YUM\n",
      "📡 [181/181] ZBRA\n",
      "✅ Done. Saved to market_cap.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "POLYGON_KEY = \"ML8KNIhH8hbBS9Cv_w9YcHfwqEpp3IQZ\"  # 🔐 Replace with your actual API key\n",
    "\n",
    "# Step 1: Load all unique tickers from stocks.csv\n",
    "df = pd.read_csv(\"stocks.csv\", parse_dates=[\"date\"])\n",
    "symbols = sorted(df[\"symbol\"].dropna().unique())\n",
    "\n",
    "# Step 2: Query Polygon's ticker details\n",
    "def get_market_cap(symbol):\n",
    "    url = f\"https://api.polygon.io/v3/reference/tickers/{symbol.upper()}\"\n",
    "    params = {\"apiKey\": POLYGON_KEY}\n",
    "    try:\n",
    "        res = requests.get(url, params=params)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        market_cap = data.get(\"results\", {}).get(\"market_cap\", None)\n",
    "        name = data.get(\"results\", {}).get(\"name\", \"\")\n",
    "        return {\"symbol\": symbol, \"market_cap\": market_cap, \"company_name\": name}\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {symbol}: {e}\")\n",
    "        return {\"symbol\": symbol, \"market_cap\": None, \"company_name\": None}\n",
    "\n",
    "# Step 3: Loop with rate-limiting (optional for safety)\n",
    "results = []\n",
    "for i, sym in enumerate(symbols, 1):\n",
    "    print(f\"📡 [{i}/{len(symbols)}] {sym}\")\n",
    "    info = get_market_cap(sym)\n",
    "    results.append(info)\n",
    "    time.sleep(0.5)  # ✅ adjust if needed — less aggressive with paid plan\n",
    "\n",
    "# Step 4: Save to CSV\n",
    "market_cap_df = pd.DataFrame(results)\n",
    "market_cap_df = market_cap_df.dropna(subset=[\"market_cap\"])\n",
    "market_cap_df.to_csv(\"market_cap.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done. Saved to market_cap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ed30ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated market_cap.csv with cap_score and cap_emoji columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your raw market cap data\n",
    "df = pd.read_csv(\"market_cap.csv\")\n",
    "\n",
    "# Step 1: Parse market cap strings like '3.2T', '750B', '44M'\n",
    "def parse_market_cap(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    value = str(value).upper().replace(\"$\", \"\").strip()\n",
    "    try:\n",
    "        if value.endswith(\"T\"):\n",
    "            return float(value[:-1]) * 1e12\n",
    "        elif value.endswith(\"B\"):\n",
    "            return float(value[:-1]) * 1e9\n",
    "        elif value.endswith(\"M\"):\n",
    "            return float(value[:-1]) * 1e6\n",
    "        else:\n",
    "            return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"cap_numeric\"] = df[\"market_cap\"].apply(parse_market_cap)\n",
    "\n",
    "# Step 2: Assign cap score (1 = mega, 5 = small)\n",
    "def get_cap_score(cap):\n",
    "    if pd.isna(cap):\n",
    "        return 5  # treat unknowns as smallest\n",
    "    elif cap >= 200e9:\n",
    "        return 1\n",
    "    elif cap >= 50e9:\n",
    "        return 2\n",
    "    elif cap >= 10e9:\n",
    "        return 3\n",
    "    elif cap >= 2e9:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "df[\"cap_score\"] = df[\"cap_numeric\"].apply(get_cap_score)\n",
    "\n",
    "# Step 3: Optional emoji mapping (for Streamlit)\n",
    "emoji_map = {1: \"🏆\", 2: \"🥈\", 3: \"🥉\", 4: \"🟢\", 5: \"🟡\"}\n",
    "df[\"cap_emoji\"] = df[\"cap_score\"].map(emoji_map)\n",
    "\n",
    "# Step 4: Save cleaned version\n",
    "output_cols = [\"symbol\", \"company_name\", \"market_cap\", \"cap_numeric\", \"cap_score\", \"cap_emoji\"]\n",
    "df[output_cols].to_csv(\"market_cap.csv\", index=False)\n",
    "\n",
    "print(\"✅ Updated market_cap.csv with cap_score and cap_emoji columns.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
