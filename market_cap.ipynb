{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d553a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¡ [1/181] AAPL\n",
      "ğŸ“¡ [2/181] ABNB\n",
      "ğŸ“¡ [3/181] ACN\n",
      "ğŸ“¡ [4/181] ADBE\n",
      "ğŸ“¡ [5/181] ADI\n",
      "ğŸ“¡ [6/181] ADM\n",
      "ğŸ“¡ [7/181] ADSK\n",
      "ğŸ“¡ [8/181] AKAM\n",
      "ğŸ“¡ [9/181] AMAT\n",
      "ğŸ“¡ [10/181] AMD\n",
      "ğŸ“¡ [11/181] AMZN\n",
      "ğŸ“¡ [12/181] ANET\n",
      "ğŸ“¡ [13/181] APH\n",
      "ğŸ“¡ [14/181] APTV\n",
      "ğŸ“¡ [15/181] AVGO\n",
      "ğŸ“¡ [16/181] AZO\n",
      "ğŸ“¡ [17/181] BBY\n",
      "ğŸ“¡ [18/181] BF.B\n",
      "ğŸ“¡ [19/181] BG\n",
      "ğŸ“¡ [20/181] BKNG\n",
      "ğŸ“¡ [21/181] CAG\n",
      "ğŸ“¡ [22/181] CCL\n",
      "ğŸ“¡ [23/181] CDNS\n",
      "ğŸ“¡ [24/181] CDW\n",
      "ğŸ“¡ [25/181] CHD\n",
      "ğŸ“¡ [26/181] CHTR\n",
      "ğŸ“¡ [27/181] CL\n",
      "ğŸ“¡ [28/181] CLX\n",
      "ğŸ“¡ [29/181] CMCSA\n",
      "ğŸ“¡ [30/181] CMG\n",
      "ğŸ“¡ [31/181] COST\n",
      "ğŸ“¡ [32/181] CPB\n",
      "ğŸ“¡ [33/181] CRM\n",
      "ğŸ“¡ [34/181] CRWD\n",
      "ğŸ“¡ [35/181] CSCO\n",
      "ğŸ“¡ [36/181] CTSH\n",
      "ğŸ“¡ [37/181] CZR\n",
      "ğŸ“¡ [38/181] DASH\n",
      "ğŸ“¡ [39/181] DDOG\n",
      "ğŸ“¡ [40/181] DECK\n",
      "ğŸ“¡ [41/181] DELL\n",
      "ğŸ“¡ [42/181] DG\n",
      "ğŸ“¡ [43/181] DHI\n",
      "ğŸ“¡ [44/181] DIS\n",
      "ğŸ“¡ [45/181] DLTR\n",
      "ğŸ“¡ [46/181] DPZ\n",
      "ğŸ“¡ [47/181] DRI\n",
      "ğŸ“¡ [48/181] EA\n",
      "ğŸ“¡ [49/181] EBAY\n",
      "ğŸ“¡ [50/181] EL\n",
      "ğŸ“¡ [51/181] ENPH\n",
      "ğŸ“¡ [52/181] EPAM\n",
      "ğŸ“¡ [53/181] EXPE\n",
      "ğŸ“¡ [54/181] F\n",
      "ğŸ“¡ [55/181] FFIV\n",
      "ğŸ“¡ [56/181] FICO\n",
      "ğŸ“¡ [57/181] FOX\n",
      "ğŸ“¡ [58/181] FOXA\n",
      "ğŸ“¡ [59/181] FSLR\n",
      "ğŸ“¡ [60/181] FTNT\n",
      "ğŸ“¡ [61/181] GDDY\n",
      "ğŸ“¡ [62/181] GEN\n",
      "ğŸ“¡ [63/181] GIS\n",
      "ğŸ“¡ [64/181] GLW\n",
      "ğŸ“¡ [65/181] GM\n",
      "ğŸ“¡ [66/181] GOOG\n",
      "ğŸ“¡ [67/181] GOOGL\n",
      "ğŸ“¡ [68/181] GPC\n",
      "ğŸ“¡ [69/181] GRMN\n",
      "ğŸ“¡ [70/181] HAS\n",
      "ğŸ“¡ [71/181] HD\n",
      "ğŸ“¡ [72/181] HLT\n",
      "ğŸ“¡ [73/181] HPE\n",
      "ğŸ“¡ [74/181] HPQ\n",
      "ğŸ“¡ [75/181] HRL\n",
      "ğŸ“¡ [76/181] HSY\n",
      "ğŸ“¡ [77/181] IBM\n",
      "ğŸ“¡ [78/181] INTC\n",
      "ğŸ“¡ [79/181] INTU\n",
      "ğŸ“¡ [80/181] IPG\n",
      "ğŸ“¡ [81/181] IT\n",
      "ğŸ“¡ [82/181] JBL\n",
      "ğŸ“¡ [83/181] K\n",
      "ğŸ“¡ [84/181] KDP\n",
      "ğŸ“¡ [85/181] KEYS\n",
      "ğŸ“¡ [86/181] KHC\n",
      "ğŸ“¡ [87/181] KLAC\n",
      "ğŸ“¡ [88/181] KMB\n",
      "ğŸ“¡ [89/181] KMX\n",
      "ğŸ“¡ [90/181] KO\n",
      "ğŸ“¡ [91/181] KR\n",
      "ğŸ“¡ [92/181] KVUE\n",
      "ğŸ“¡ [93/181] LEN\n",
      "ğŸ“¡ [94/181] LKQ\n",
      "ğŸ“¡ [95/181] LOW\n",
      "ğŸ“¡ [96/181] LRCX\n",
      "ğŸ“¡ [97/181] LULU\n",
      "ğŸ“¡ [98/181] LVS\n",
      "ğŸ“¡ [99/181] LW\n",
      "ğŸ“¡ [100/181] LYV\n",
      "ğŸ“¡ [101/181] MAR\n",
      "ğŸ“¡ [102/181] MCD\n",
      "ğŸ“¡ [103/181] MCHP\n",
      "ğŸ“¡ [104/181] MDLZ\n",
      "ğŸ“¡ [105/181] META\n",
      "ğŸ“¡ [106/181] MGM\n",
      "ğŸ“¡ [107/181] MHK\n",
      "ğŸ“¡ [108/181] MKC\n",
      "ğŸ“¡ [109/181] MNST\n",
      "ğŸ“¡ [110/181] MO\n",
      "ğŸ“¡ [111/181] MPWR\n",
      "ğŸ“¡ [112/181] MSFT\n",
      "ğŸ“¡ [113/181] MSI\n",
      "ğŸ“¡ [114/181] MTCH\n",
      "ğŸ“¡ [115/181] MU\n",
      "ğŸ“¡ [116/181] NCLH\n",
      "ğŸ“¡ [117/181] NFLX\n",
      "ğŸ“¡ [118/181] NKE\n",
      "ğŸ“¡ [119/181] NOW\n",
      "ğŸ“¡ [120/181] NTAP\n",
      "ğŸ“¡ [121/181] NVDA\n",
      "ğŸ“¡ [122/181] NVR\n",
      "ğŸ“¡ [123/181] NWS\n",
      "ğŸ“¡ [124/181] NWSA\n",
      "ğŸ“¡ [125/181] NXPI\n",
      "ğŸ“¡ [126/181] OMC\n",
      "ğŸ“¡ [127/181] ON\n",
      "ğŸ“¡ [128/181] ORCL\n",
      "ğŸ“¡ [129/181] ORLY\n",
      "ğŸ“¡ [130/181] PANW\n",
      "ğŸ“¡ [131/181] PEP\n",
      "ğŸ“¡ [132/181] PG\n",
      "ğŸ“¡ [133/181] PHM\n",
      "ğŸ“¡ [134/181] PLTR\n",
      "ğŸ“¡ [135/181] PM\n",
      "ğŸ“¡ [136/181] POOL\n",
      "ğŸ“¡ [137/181] PSKY\n",
      "ğŸ“¡ [138/181] PTC\n",
      "ğŸ“¡ [139/181] QCOM\n",
      "ğŸ“¡ [140/181] RCL\n",
      "ğŸ“¡ [141/181] RL\n",
      "ğŸ“¡ [142/181] ROP\n",
      "ğŸ“¡ [143/181] ROST\n",
      "ğŸ“¡ [144/181] SBUX\n",
      "ğŸ“¡ [145/181] SJM\n",
      "ğŸ“¡ [146/181] SMCI\n",
      "ğŸ“¡ [147/181] SNPS\n",
      "ğŸ“¡ [148/181] STX\n",
      "ğŸ“¡ [149/181] STZ\n",
      "ğŸ“¡ [150/181] SWKS\n",
      "ğŸ“¡ [151/181] SYY\n",
      "ğŸ“¡ [152/181] T\n",
      "ğŸ“¡ [153/181] TAP\n",
      "ğŸ“¡ [154/181] TDY\n",
      "ğŸ“¡ [155/181] TEL\n",
      "ğŸ“¡ [156/181] TER\n",
      "ğŸ“¡ [157/181] TGT\n",
      "ğŸ“¡ [158/181] TJX\n",
      "ğŸ“¡ [159/181] TKO\n",
      "ğŸ“¡ [160/181] TMUS\n",
      "ğŸ“¡ [161/181] TPR\n",
      "ğŸ“¡ [162/181] TRMB\n",
      "ğŸ“¡ [163/181] TSCO\n",
      "ğŸ“¡ [164/181] TSLA\n",
      "ğŸ“¡ [165/181] TSN\n",
      "ğŸ“¡ [166/181] TTD\n",
      "ğŸ“¡ [167/181] TTWO\n",
      "ğŸ“¡ [168/181] TXN\n",
      "ğŸ“¡ [169/181] TYL\n",
      "ğŸ“¡ [170/181] ULTA\n",
      "ğŸ“¡ [171/181] VRSN\n",
      "ğŸ“¡ [172/181] VZ\n",
      "ğŸ“¡ [173/181] WBA\n",
      "ğŸ“¡ [174/181] WBD\n",
      "ğŸ“¡ [175/181] WDAY\n",
      "ğŸ“¡ [176/181] WDC\n",
      "ğŸ“¡ [177/181] WMT\n",
      "ğŸ“¡ [178/181] WSM\n",
      "ğŸ“¡ [179/181] WYNN\n",
      "ğŸ“¡ [180/181] YUM\n",
      "ğŸ“¡ [181/181] ZBRA\n",
      "âœ… Done. Saved to market_cap.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "POLYGON_KEY = \"ML8KNIhH8hbBS9Cv_w9YcHfwqEpp3IQZ\"  # ğŸ” Replace with your actual API key\n",
    "\n",
    "# Step 1: Load all unique tickers from stocks.csv\n",
    "df = pd.read_csv(\"stocks.csv\", parse_dates=[\"date\"])\n",
    "symbols = sorted(df[\"symbol\"].dropna().unique())\n",
    "\n",
    "# Step 2: Query Polygon's ticker details\n",
    "def get_market_cap(symbol):\n",
    "    url = f\"https://api.polygon.io/v3/reference/tickers/{symbol.upper()}\"\n",
    "    params = {\"apiKey\": POLYGON_KEY}\n",
    "    try:\n",
    "        res = requests.get(url, params=params)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        market_cap = data.get(\"results\", {}).get(\"market_cap\", None)\n",
    "        name = data.get(\"results\", {}).get(\"name\", \"\")\n",
    "        return {\"symbol\": symbol, \"market_cap\": market_cap, \"company_name\": name}\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {symbol}: {e}\")\n",
    "        return {\"symbol\": symbol, \"market_cap\": None, \"company_name\": None}\n",
    "\n",
    "# Step 3: Loop with rate-limiting (optional for safety)\n",
    "results = []\n",
    "for i, sym in enumerate(symbols, 1):\n",
    "    print(f\"ğŸ“¡ [{i}/{len(symbols)}] {sym}\")\n",
    "    info = get_market_cap(sym)\n",
    "    results.append(info)\n",
    "    time.sleep(0.5)  # âœ… adjust if needed â€” less aggressive with paid plan\n",
    "\n",
    "# Step 4: Save to CSV\n",
    "market_cap_df = pd.DataFrame(results)\n",
    "market_cap_df = market_cap_df.dropna(subset=[\"market_cap\"])\n",
    "market_cap_df.to_csv(\"market_cap.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Done. Saved to market_cap.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ed30ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated market_cap.csv with cap_score and cap_emoji columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your raw market cap data\n",
    "df = pd.read_csv(\"market_cap.csv\")\n",
    "\n",
    "# Step 1: Parse market cap strings like '3.2T', '750B', '44M'\n",
    "def parse_market_cap(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    value = str(value).upper().replace(\"$\", \"\").strip()\n",
    "    try:\n",
    "        if value.endswith(\"T\"):\n",
    "            return float(value[:-1]) * 1e12\n",
    "        elif value.endswith(\"B\"):\n",
    "            return float(value[:-1]) * 1e9\n",
    "        elif value.endswith(\"M\"):\n",
    "            return float(value[:-1]) * 1e6\n",
    "        else:\n",
    "            return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"cap_numeric\"] = df[\"market_cap\"].apply(parse_market_cap)\n",
    "\n",
    "# Step 2: Assign cap score (1 = mega, 5 = small)\n",
    "def get_cap_score(cap):\n",
    "    if pd.isna(cap):\n",
    "        return 5  # treat unknowns as smallest\n",
    "    elif cap >= 200e9:\n",
    "        return 1\n",
    "    elif cap >= 50e9:\n",
    "        return 2\n",
    "    elif cap >= 10e9:\n",
    "        return 3\n",
    "    elif cap >= 2e9:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "df[\"cap_score\"] = df[\"cap_numeric\"].apply(get_cap_score)\n",
    "\n",
    "# Step 3: Optional emoji mapping (for Streamlit)\n",
    "emoji_map = {1: \"ğŸ†\", 2: \"ğŸ¥ˆ\", 3: \"ğŸ¥‰\", 4: \"ğŸŸ¢\", 5: \"ğŸŸ¡\"}\n",
    "df[\"cap_emoji\"] = df[\"cap_score\"].map(emoji_map)\n",
    "\n",
    "# Step 4: Save cleaned version\n",
    "output_cols = [\"symbol\", \"company_name\", \"market_cap\", \"cap_numeric\", \"cap_score\", \"cap_emoji\"]\n",
    "df[output_cols].to_csv(\"market_cap.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Updated market_cap.csv with cap_score and cap_emoji columns.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
